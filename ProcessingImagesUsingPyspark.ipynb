{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee6e5a10-c022-4152-92ba-1dc5ce8608d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark session started.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/28 12:30:02 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "# Setup Spark \n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"BMPImageProcessing--DA2(BIG DATA)\").getOrCreate()\n",
    "print(\"Spark session started.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b70b0669-d7c5-44d9-b349-3ac2bf98c7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 60 BMP images.\n",
      "\n",
      "+--------------------+--------------------+------+--------------------+\n",
      "|                path|    modificationTime|length|             content|\n",
      "+--------------------+--------------------+------+--------------------+\n",
      "|file:/home/dhines...|2025-09-20 22:33:...|691254|[42 4D 36 8C 0A 0...|\n",
      "|file:/home/dhines...|2025-09-20 22:33:...|691254|[42 4D 36 8C 0A 0...|\n",
      "|file:/home/dhines...|2025-09-20 22:33:...|691254|[42 4D 36 8C 0A 0...|\n",
      "|file:/home/dhines...|2025-09-20 22:33:...|691254|[42 4D 36 8C 0A 0...|\n",
      "|file:/home/dhines...|2025-09-20 22:33:...|691254|[42 4D 36 8C 0A 0...|\n",
      "+--------------------+--------------------+------+--------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# Load BMP Images \n",
    "image_dir = \"/home/dhinesh-fedor/Documents/BIG_DATA_DA2/Dataset/\"  # folder with .bmp images\n",
    "\n",
    "# Load BMP images as binary files\n",
    "images_df = spark.read.format(\"binaryFile\") \\\n",
    "    .option(\"pathGlobFilter\", \"*.bmp\") \\\n",
    "    .load(image_dir)\n",
    "\n",
    "print(f\"Loaded {images_df.count()} BMP images.\\n\")\n",
    "images_df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "faccea11-7039-4f6c-926a-1bdec6af3466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------+--------------------+--------------------+\n",
      "|                path|    modificationTime|length|             content|            features|\n",
      "+--------------------+--------------------+------+--------------------+--------------------+\n",
      "|file:/home/dhines...|2025-09-20 22:33:...|691254|[42 4D 36 8C 0A 0...|[0.42745098039215...|\n",
      "|file:/home/dhines...|2025-09-20 22:33:...|691254|[42 4D 36 8C 0A 0...|[0.15686274509803...|\n",
      "|file:/home/dhines...|2025-09-20 22:33:...|691254|[42 4D 36 8C 0A 0...|[0.25490196078431...|\n",
      "|file:/home/dhines...|2025-09-20 22:33:...|691254|[42 4D 36 8C 0A 0...|[0.15294117647058...|\n",
      "|file:/home/dhines...|2025-09-20 22:33:...|691254|[42 4D 36 8C 0A 0...|[0.16470588235294...|\n",
      "+--------------------+--------------------+------+--------------------+--------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# Preprocess & Feature Extraction \n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "def bmp_to_vector(binary):\n",
    "    try:\n",
    "        img = Image.open(io.BytesIO(binary)).convert('L').resize((32,32))  # grayscale + resize\n",
    "        arr = np.array(img).flatten()/255.0  # normalize\n",
    "        return Vectors.dense(arr.tolist())   # convert to Spark Vector\n",
    "    except Exception as e:\n",
    "        print(\"Error processing image:\", e)\n",
    "        return Vectors.dense([0.0]*1024)  # fallback\n",
    "\n",
    "vector_udf = udf(bmp_to_vector, VectorUDT())\n",
    "images_vector_df = images_df.withColumn(\"features\", vector_udf(\"content\"))\n",
    "\n",
    "images_vector_df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "151f1ee4-d5eb-4614-bd09-fbeb2d9ad9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/09/28 12:30:38 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+\n",
      "|                path|cluster|\n",
      "+--------------------+-------+\n",
      "|file:/home/dhines...|      0|\n",
      "|file:/home/dhines...|      2|\n",
      "|file:/home/dhines...|      0|\n",
      "|file:/home/dhines...|      0|\n",
      "|file:/home/dhines...|      1|\n",
      "|file:/home/dhines...|      0|\n",
      "|file:/home/dhines...|      0|\n",
      "|file:/home/dhines...|      0|\n",
      "|file:/home/dhines...|      0|\n",
      "|file:/home/dhines...|      0|\n",
      "+--------------------+-------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "# Apply Clustering (KMeans) \n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Convert array to Spark vector\n",
    "kmeans = KMeans(k=3, seed=42, featuresCol=\"features\", predictionCol=\"cluster\")\n",
    "model = kmeans.fit(images_vector_df)\n",
    "clustered_df = model.transform(images_vector_df)\n",
    "\n",
    "clustered_df.select(\"path\", \"cluster\").show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ce7c5cb-7217-418b-bf92-fe0e6e57b0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 45:======================================>                  (8 + 4) / 12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|cluster|count|\n",
      "+-------+-----+\n",
      "|      1|   32|\n",
      "|      2|    9|\n",
      "|      0|   19|\n",
      "+-------+-----+\n",
      "\n",
      "\n",
      "Clusters analyzed. Each cluster groups visually similar BMP images.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Analyze Clusters \n",
    "clustered_df.groupBy(\"cluster\").count().show()\n",
    "print(\"\\nClusters analyzed. Each cluster groups visually similar BMP images.\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
